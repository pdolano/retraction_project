{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "418cf4ae-80a7-4e3c-ad87-531fe3d60ce4",
   "metadata": {},
   "source": [
    "# 2b. Extracting Country and Year Distribution of Retracted Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f538c-80be-47fd-ab35-c57b8b5c0bdb",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706c66e-dd40-44d1-adc9-1710de33491d",
   "metadata": {},
   "source": [
    "This Notebook analyzes the country and year distribution of our sample of retracted papers. In other words, **it extracts the year and country distribution** of the set of retracted papers under investigation.\n",
    "\n",
    "The Notebook takes as input the JSON files with all the bibliographic information that OpenAlex had for our retracted papers, which we dowloaded in **Notebook 2a**. The bucket distribution that it produces is then in turn be used by **Notebook 3a** to download a set of non-retracted papers with the same year and country distribution as our original retracted paper data set (Notebooks 2c extracts abstract information for our retracted papers. Its labeling as belonging to the \"2\" series indicates that it performs data extraction and pre-processing for retracted articles).\n",
    "\n",
    "The **workflow** of the Notebook is therefore set up as follows:\n",
    "\n",
    "- Input: **a set of JSON files** with all the bibliographic information that we downloaded from OpenAlex for our retracted papers.\n",
    "- Output: **one .csv file** with the number of retracted papers for each year and country bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d07f2df-447a-43c6-b72f-3a2e771eaf76",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6201d845-96a9-4c08-97de-4db0f357c5d9",
   "metadata": {},
   "source": [
    "Let us start by importing the various libraries that we will use in the Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62e3d5a-44f3-490f-a408-c46ca9c9a879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c527f00-d9a4-4ee8-ba73-fbecd7673abe",
   "metadata": {},
   "source": [
    "## Input / Output Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f0564-a259-4359-8443-5b415c0d33e7",
   "metadata": {},
   "source": [
    "Input parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5853a441-d2b9-458b-af32-a001c7964b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# File path of the directory with .json files\n",
    "\n",
    "input_path = '../data/json_files/cell_biology/retracted'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720dcb6-bfdb-4022-a8d1-a9ee73235ff9",
   "metadata": {},
   "source": [
    "Output parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4979d5-a6e6-4f58-a3f0-17beb4343eee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# File path for .csv file with results\n",
    "\n",
    "output_path = '../data/buckets/cell_biology/cell_bio_buckets.csv'\n",
    "\n",
    "# File path for .csv file with value counts\n",
    "\n",
    "output_path_value_counts = '../data/buckets/cell_biology/cell_bio_buckets_value.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6613abda-3be8-4b3a-a477-0f7a0aa035e7",
   "metadata": {},
   "source": [
    "## Output: Extracting Year and Country Buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb7d0ae-7131-4b7c-bd8b-26a4d094c2f1",
   "metadata": {},
   "source": [
    "\n",
    "We can now go ahead and analyze the .json files for our retracted papers and find the amount of papers per year and country bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8b4b72-70cd-491b-ad2c-777eb380d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country and year distribution of 9089 papers complete, result saved to ../data/buckets/cell_biology/cell_bio_buckets.csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create list with name of headers to be written in output .csv file\n",
    "headers = ['file_name', 'author_country', 'publication_year', 'abstract_info', 'ngram_info', 'error']\n",
    "\n",
    "# Initialize paper count and data list for DataFrame\n",
    "paper_count = 0\n",
    "data_list = []\n",
    "\n",
    "# Open .csv file to write values for each bucket\n",
    "with open(output_path, mode='w', newline='') as file:\n",
    "    # Initialize writer\n",
    "    writer = csv.DictWriter(file, fieldnames=headers)\n",
    "    \n",
    "    # Write header names\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Create loop to iterate over all .json files in input directory\n",
    "    for filename in os.listdir(input_path):\n",
    "        # Update paper count\n",
    "        paper_count += 1\n",
    "\n",
    "        # If clause to make sure we only loop through .json files\n",
    "        if filename.endswith('.json'):\n",
    "            # Construct full file path for current .json file in loop iteration\n",
    "            file_path = os.path.join(input_path, filename)\n",
    "\n",
    "            # Initialize error message and other variables\n",
    "            error_message = \"\"\n",
    "            author_country = \"N/A\"\n",
    "            ngram_info = False\n",
    "\n",
    "            # Try to open and read .json file in current loop iteration\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "                    # Read .json file\n",
    "                    content = json_file.read()\n",
    "\n",
    "                    # If clause to account for situation in which .json file is empty\n",
    "                    if not content:\n",
    "                        raise ValueError(\"File is empty\")\n",
    "\n",
    "                    # Load content of current .json file into data variable\n",
    "                    data = json.loads(content)\n",
    "\n",
    "            # Clause to update error message if reading of .json file fails\n",
    "            except Exception as e:\n",
    "                error_message = str(e)\n",
    "\n",
    "            # Extract the country code from data variable\n",
    "            if 'authorships' in data:\n",
    "                for authorship in data['authorships']:\n",
    "                    if 'institutions' in authorship and any(inst.get('country_code') for inst in authorship['institutions']):\n",
    "                        author_country = next((inst['country_code'] for inst in authorship['institutions'] if 'country_code' in inst), \"N/A\")\n",
    "                        break\n",
    "\n",
    "            # Extract ngrams information from data variable\n",
    "            ngrams_url = data.get('ngrams_url', '')\n",
    "            if ngrams_url.startswith('https://api.'):\n",
    "                ngram_info = True\n",
    "\n",
    "            # Extract publication year from data variable\n",
    "            publication_year = data.get('publication_year', 'N/A') if not error_message else 'N/A'\n",
    "\n",
    "            # Extract abstract info from data variable\n",
    "            abstract_info = bool(data.get('abstract_inverted_index')) if not error_message else False\n",
    "\n",
    "            # Create row of data\n",
    "            row = {\n",
    "                'file_name': filename,\n",
    "                'author_country': author_country,\n",
    "                'publication_year': publication_year,\n",
    "                'abstract_info': abstract_info,\n",
    "                'ngram_info': ngram_info,\n",
    "                'error': error_message\n",
    "            }\n",
    "\n",
    "            # Write data or error to .csv file\n",
    "            writer.writerow(row)\n",
    "\n",
    "            # Append data to list for DataFrame\n",
    "            data_list.append(row)\n",
    "\n",
    "# Convert data list to DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Write confirmation message\n",
    "print(f\"Country and year distribution of {paper_count} papers complete, result saved to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719cd073-637d-49d4-9951-ed766efd8857",
   "metadata": {},
   "source": [
    "Let us also create another data frame with the value counts per country and year, and save the results into a .csv file for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49003f83-74a4-4596-8b2f-70776848fc20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts per country and year saved to value_counts.csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a DataFrame with value counts per country and year\n",
    "\n",
    "value_counts_df = df.groupby(['author_country', 'publication_year']).size().reset_index(name='count')\n",
    "\n",
    "# Save the value counts DataFrame to a CSV file\n",
    "\n",
    "value_counts_df.to_csv(output_path_value_counts, index=False)\n",
    "\n",
    "# Write confirmation message\n",
    "\n",
    "print(\"Value counts per country and year saved to value_counts.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a8dbe-8483-4a8b-b33f-bc9057268197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
