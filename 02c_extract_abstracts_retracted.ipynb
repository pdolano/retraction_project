{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c0d779-9f5c-4cc8-9229-2154c7bf0fe6",
   "metadata": {},
   "source": [
    "# 2c. Extract Abstracts for Retracted Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ad1d4-6973-4144-b34e-84fa2296c3ff",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f358f2-9bf8-4585-91d6-9b75be1b6a4d",
   "metadata": {},
   "source": [
    "This Notebook **extracts abstracts** from the .json files that we downloaded from OpenAlex **for our retracted papers**. It does so by extracting inverted word indeces directly from the .json files, and then reconstructing them to obtain standard abstract text.\n",
    "\n",
    "The Notebook thus takes as input the .json files that were downloaded in **Notebook 2a**. The reconstructed abstract generated in here will in turn be used as input in **Notebook 5**, when we generated the whole corpus with both retracted and non-retracted text to be used to train our model\n",
    "\n",
    "The **workflow** of has been set to be as follows:\n",
    "\n",
    "- Input: all the **.json files** for all retracted papers under investigation.\n",
    "- Output: **one .csv file** with the reconstructed abstracts, along with the DOI, year, and country of each paper, and **one .csv file** with log information about the extraction and reconstruction process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e243347-13bd-44ca-ab3a-a41de4e80465",
   "metadata": {},
   "source": [
    "## Input / Output Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dc1d96-0d92-4e02-9696-d9205a7613f7",
   "metadata": {},
   "source": [
    "Input parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9923da9-d01b-4f5f-9398-28f319d26ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Input path\n",
    "\n",
    "input_path = '../data/json_files/cell_biology/retracted'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb7273-9c36-4fcc-8939-3bb7a38f98e0",
   "metadata": {},
   "source": [
    "Output parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb4aecbd-7433-4b87-9169-44f25727858a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Output path for abstracts\n",
    "\n",
    "output_path_abstracts = '../data/abstracts/cell_biology/retracted/retracted_cell_biology_abstracts.csv'\n",
    "\n",
    "# Output path for logs\n",
    "\n",
    "output_path_logs = '../data/logs/retracted_abstract_extraction_log.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae060ff-f297-411b-bb86-0b41f59261c3",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a88944e2-31ad-497d-9b7a-507db16ed5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c05fc24-0b42-440e-8bf9-3ff5914cd2b4",
   "metadata": {},
   "source": [
    "## Extracting Abstracts from JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d60645a-0516-4aa6-8b1a-c270420eefd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define function to remove non-printable characters\n",
    "\n",
    "def remove_non_printable(text):\n",
    "    printable = set(string.printable)\n",
    "    return ''.join(filter(lambda x: x in printable, text))\n",
    "\n",
    "# Initialize lists to store data and log entries\n",
    "\n",
    "data = []\n",
    "log_entries = []\n",
    "\n",
    "# Create list with names of all files in input directory\n",
    "\n",
    "files = os.listdir(input_path)\n",
    "\n",
    "# For loop to iterate over all .json files in input directory\n",
    "\n",
    "for i, filename in enumerate(files):\n",
    "    \n",
    "    # If sentence to make sure we only process .json files\n",
    "    \n",
    "    if filename.endswith('.json'):\n",
    "        \n",
    "        # Construct full path for current .json file in loop\n",
    "        \n",
    "        file_path = os.path.join(input_path, filename)\n",
    "        \n",
    "        # Try sentence to account for errors reading current .json file\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # Open and read current .json file\n",
    "            \n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                \n",
    "                # Write content of current .json file into content variable\n",
    "                \n",
    "                content = json.load(file)\n",
    "                \n",
    "                # Extract DOI of article associated to current .json file\n",
    "                \n",
    "                doi = filename.replace('.json', '')\n",
    "\n",
    "                # Get inverted index from content variable \n",
    "                \n",
    "                abstract_inverted_index = content.get('abstract_inverted_index', {})\n",
    "                \n",
    "                # If sentence to make sure we only process non-empty word indeces\n",
    "                \n",
    "                if abstract_inverted_index:\n",
    "                    \n",
    "                    # Initialize list of tuples with each word and the position that it occupies in the abstract text\n",
    "                    \n",
    "                    index_word_pairs = [(index, word) for word, indices in abstract_inverted_index.items() for index in indices]\n",
    "                    \n",
    "                    # Sort list according to the position of each word in the abstract text\n",
    "                    \n",
    "                    index_word_pairs.sort()\n",
    "                    \n",
    "                    # Reconstruct abstract by adding words in list of tuples in the order of their occurrence in the text\n",
    "                    # We add a space at the beginning and strip it at the end\n",
    "                    \n",
    "                    abstract_text = ' '.join(word for _, word in index_word_pairs).strip()\n",
    "                   \n",
    "                    # Create string with delimiter characters to be removed from reconstructed text\n",
    "                    \n",
    "                    delimiters = \",;|{}\\n\\r\\t[]<>\"\n",
    "                    \n",
    "                    # For loop to iterate over all delimiters in delimiter string\n",
    "                    \n",
    "                    for delimiter in delimiters:\n",
    "                        \n",
    "                        # Replace current delimiter in loop with blank space\n",
    "                        \n",
    "                        abstract_text = abstract_text.replace(delimiter, ' ')\n",
    "                        \n",
    "                    # Call function to remove non printable characters from reconstructed text \n",
    "                        \n",
    "                    abstract_text = remove_non_printable(abstract_text)\n",
    "                    \n",
    "                # Else sentence to account for situation in which inverted index is empty\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    log_entries.append({'filename': filename, 'success': False, 'message': 'No abstract_inverted_index provided'})\n",
    "                    \n",
    "                    continue\n",
    "                    \n",
    "                # Initialize author_country string\n",
    "                \n",
    "                author_country = 'Unknown'  # Default value\n",
    "                \n",
    "                # If clause to check if authorship information is present in content variable\n",
    "                \n",
    "                if 'authorships' in content:\n",
    "                    \n",
    "                    # For loop to iterate over authorsips list\n",
    "                    \n",
    "                    for authorship in content['authorships']:\n",
    "                        \n",
    "                        # Extract country code from institution of first author for which information is available\n",
    "                        \n",
    "                        if 'institutions' in authorship and any(inst.get('country_code') for inst in authorship['institutions']):\n",
    "                            \n",
    "                            author_country = next((inst['country_code'] for inst in authorship['institutions'] if 'country_code' in inst), \"Unknown\")\n",
    "                            \n",
    "                            break\n",
    "\n",
    "                # Extract publication year from content variable\n",
    "                \n",
    "                year = content.get('publication_year', 'Unknown')\n",
    "                \n",
    "                # Check for the presence of \"retract%\" or \"withdraw%\" in abstract_text\n",
    "                \n",
    "                retracted_flag = any(word in abstract_text.lower() for word in [\"retract\", \"withdraw\", \"retracted\", \"retraction\", \"withdrew\", \"withdrawal\",\"withdrawn\", \"retracts\"])\n",
    "\n",
    "                # Update data variable with reconstructed text and additional information\n",
    "                \n",
    "                data.append({\n",
    "                    'abstract_text': f'\"{abstract_text}\"',  # Ensure the text is surrounded by double quotes\n",
    "                    'target': 1,\n",
    "                    'doi': doi,\n",
    "                    'country': author_country,\n",
    "                    'year': year,\n",
    "                    'ret_flag': retracted_flag\n",
    "                })\n",
    "\n",
    "                # Update log variable  with success message\n",
    "                \n",
    "                log_entries.append({'filename': filename, 'success': True, 'message': 'Processed successfully'})\n",
    "        \n",
    "        \n",
    "        # Clause to account for errors in reading the current .json file\n",
    "        \n",
    "        except Exception as e:\n",
    "            \n",
    "            # Update log variable with current error message\n",
    "            \n",
    "            log_entries.append({'filename': filename, 'success': False, 'message': f'Error processing file - {str(e)}'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b3df5-028f-4ca4-8aaa-a50764544e42",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af43ef2d-222c-4054-bc3e-5b71c8f8760e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create data frame with content of data list and pipe symbol as delimiter\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save content of data frame to .csv\n",
    "\n",
    "df.to_csv(output_path_abstracts, sep='|', index=False, quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "# Create data frame with content of log_entries list \n",
    "\n",
    "log_df = pd.DataFrame(log_entries)\n",
    "\n",
    "# Save content of log entry data frame to .csv\n",
    "\n",
    "log_df.to_csv(output_path_logs, index=False, quoting=csv.QUOTE_MINIMAL)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
