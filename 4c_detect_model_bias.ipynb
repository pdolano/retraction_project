{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0365e00-16d1-4225-bd68-18c583998365",
   "metadata": {},
   "source": [
    "# 4c. Detecting Year and Country Bias in Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9ca867-6b32-4b8a-b2dd-b884e7b2f1e1",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb425c2f-23fe-4df6-a8d2-389ff4b6f5f1",
   "metadata": {},
   "source": [
    "\n",
    "This Notebook **analyzes the performance of our models**, and it **analyzes whether they are biased in how they classify papers published in different years and countries**. This is the **last Notebook of the series** and it completes our analyses of retraction by means of machine learning classifiers. \n",
    "\n",
    "The Notebook takes as input the saved models that we trained in **Notebook 4b**.\n",
    "\n",
    "The **worfklow** has been set up as follows:\n",
    "\n",
    "- Input: **one .csv file** with our corpus, and **three .pkl files** with the trained models that we saved in the previous Notebook.\n",
    "- Output: **no output**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9da88f-d6e5-4c49-bb07-545e263e2728",
   "metadata": {},
   "source": [
    "# Input / Output Parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d38ea2-9f87-460f-a867-16a63cd0dc10",
   "metadata": {},
   "source": [
    "Input parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1638de04-0dc1-4ebd-b76e-d191630d638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File path to saved models\n",
    "\n",
    "input_path_models = \"../data/trained_models\"\n",
    "\n",
    "# File path to abstract corpus\n",
    "\n",
    "input_path_corpus = \"../data/final_corpus.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad0c9a5-24c5-4adc-92ad-f5d5d9e1cc81",
   "metadata": {},
   "source": [
    "There are no output parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d227ef-8b22-4567-ba2d-3bc39de99ea8",
   "metadata": {},
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcd61ac-e148-46d6-b647-bfe4313114d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfc6fe-e4a5-416e-91d5-a00e45c66738",
   "metadata": {},
   "source": [
    "# Loading Trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0006a1-de24-44e4-bbcd-db653c628b21",
   "metadata": {},
   "source": [
    "In order to start our analysis we need to load the trained models that we saved in the previous Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c541ba3b-4723-45a3-894b-37986b095e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load logistic regressor\n",
    "\n",
    "log_reg = joblib.load(input_path_models + \"/logistic_regressor.pkl\")\n",
    "\n",
    "# Load XGBoost classifier\n",
    "\n",
    "xgboost = joblib.load(input_path_models + \"/xgboost_classifier.pkl\")\n",
    "\n",
    "# Load random forest classifier\n",
    "\n",
    "rf_classifier = joblib.load(input_path_models + \"/random_forest_classifier.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34088f2-a94c-4ce4-a92e-0bf4d92f2111",
   "metadata": {},
   "source": [
    "Let us also load our abstract corpus into a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b436a8b-d595-46a6-8758-bc3b8cb91531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_text</th>\n",
       "      <th>target</th>\n",
       "      <th>doi</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>ret_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Atrial fibrosis occurs frequently with struct...</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1038_s41420-022-00895-9</td>\n",
       "      <td>CN</td>\n",
       "      <td>2022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"In Brief Purpose To determine the safety and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1097_00006982-200402000-00018</td>\n",
       "      <td>US</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Biglycan (BGN) is an important component of t...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1016_j.molonc.2016.08.002</td>\n",
       "      <td>CN</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Fusarium wilt caused by Fusarium oxysporum f....</td>\n",
       "      <td>0</td>\n",
       "      <td>10.3390_toxins12040254</td>\n",
       "      <td>CN</td>\n",
       "      <td>2020</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"The genome of Stenotrophomonas maltophilia en...</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1128_JB.00310-07</td>\n",
       "      <td>IE</td>\n",
       "      <td>2007</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       abstract_text  target  \\\n",
       "0  \"Atrial fibrosis occurs frequently with struct...       1   \n",
       "1  \"In Brief Purpose To determine the safety and ...       1   \n",
       "2  \"Biglycan (BGN) is an important component of t...       0   \n",
       "3  \"Fusarium wilt caused by Fusarium oxysporum f....       0   \n",
       "4  \"The genome of Stenotrophomonas maltophilia en...       1   \n",
       "\n",
       "                                doi country  year  ret_flag  \n",
       "0        10.1038_s41420-022-00895-9      CN  2022     False  \n",
       "1  10.1097_00006982-200402000-00018      US  2004     False  \n",
       "2      10.1016_j.molonc.2016.08.002      CN  2016     False  \n",
       "3            10.3390_toxins12040254      CN  2020     False  \n",
       "4               10.1128_JB.00310-07      IE  2007     False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create data frame with all abstracts\n",
    "\n",
    "df_corpus = pd.read_csv(input_path_corpus, encoding='latin-1')\n",
    "\n",
    "# Visualize data frame for verification\n",
    "\n",
    "df_corpus.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd421585-8de5-4e7d-9832-1cc519ce53eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Performance for Different Countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fe5da-0514-4e7b-8fda-21c70026a9f6",
   "metadata": {},
   "source": [
    "\n",
    "Finally, let us also make sure that our model gives comparable predictions for papers from different years and countries. Let us start with China:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f130987-977c-4d2b-a5b8-add227533202",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7032, 6)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_ch.shape)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Vectorize text for those papers using TF-IDF vectorization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m X_ch_tfidf = \u001b[43mtfidf\u001b[49m.transform(df_ch[\u001b[33m\"\u001b[39m\u001b[33mabstract_text\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Obtain predictions for vectorized text with logistic reg model\u001b[39;00m\n\u001b[32m     15\u001b[39m y_pred_ch = log_reg.predict(X_ch_tfidf)\n",
      "\u001b[31mNameError\u001b[39m: name 'tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtain only abstracts for papers from China and store them in data frame\n",
    "\n",
    "df_ch = df_corpus[df_corpus[\"country\"] == \"CN\"]\n",
    "\n",
    "# Visualize shape of filtered array\n",
    "\n",
    "print(df_ch.shape)\n",
    "\n",
    "# Vectorize text for those papers using TF-IDF vectorization\n",
    "\n",
    "X_ch_tfidf = tfidf.transform(df_ch[\"abstract_text\"])\n",
    "\n",
    "# Obtain predictions for vectorized text with logistic reg model\n",
    "\n",
    "y_pred_ch = log_reg.predict(X_ch_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe35676-5160-434e-af78-7bce693da39b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Obtain number of papers flagged as fraudulent\n",
    "\n",
    "y_pred_ch.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7dcb32-83c3-487f-b1e2-5118a2bfe376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Obtain number of papers that we tested in total\n",
    "\n",
    "len(y_pred_ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f2cde-d076-4163-9b43-84223a813813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute percentage of papers flagged as fraudulent for China\n",
    "\n",
    "per_fraud_china = y_pred_ch.sum() / len(y_pred_ch) * 100\n",
    "\n",
    "# Visualize result\n",
    "\n",
    "per_fraud_china "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9d688-62d9-470d-a136-cbd0cf076624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ch_fraud = df_ch[df_ch[\"target\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1ce15-0c68-40dd-9c33-6cd96cf3ed15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ch_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8069156-c5f0-4d86-a3ea-be640f8f333d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ch_fraud.shape[0] / df_ch.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3088a-95ff-46b1-aad1-159cc75376fc",
   "metadata": {},
   "source": [
    "- Let us now repeat the same steps for the US:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a5155-666e-4f1c-8660-7d6c7151d1e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Obtain only abstracts for papers from China and store them in data frame\n",
    "\n",
    "df_us = df_corpus[df_corpus[\"country\"] == \"US\"]\n",
    "\n",
    "# Visualize shape of filtered array\n",
    "\n",
    "print(df_us.shape)\n",
    "\n",
    "# Vectorize text for those papers using TF-IDF vectorization\n",
    "\n",
    "X_us_tfidf = tfidf.transform(df_us[\"abstract_text\"])\n",
    "\n",
    "# Obtain predictions for vectorized text with logistic reg model\n",
    "\n",
    "y_pred_us = log_reg.predict(X_us_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e434e-a18c-4c9b-9231-b79520e8715b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute percentage of papers flagged as fraudulent for China\n",
    "\n",
    "per_fraud_us = y_pred_us.sum() / len(y_pred_us) * 100\n",
    "\n",
    "# Visualize result\n",
    "\n",
    "per_fraud_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a141382-4e73-4c3c-a5f3-f2d7a71bfa1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_us_fraud = df_us[df_us[\"target\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ebfd0a-ef8d-4dc7-955f-dd2bd23cdd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_us_fraud.shape[0] / df_us.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ae878-82d7-4c9c-8426-b9a2fbebec9d",
   "metadata": {},
   "source": [
    "\n",
    "- It will be easier to simply write a function that performs all these operations for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca202d7-9dd7-4881-8038-ac5474fea859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_tester_country(country_code, df, vectorizer, model):\n",
    "    \n",
    "    # Obtain only abstracts for papers from China and store them in data frame\n",
    "\n",
    "    df_filtered = df[df[\"country\"] == country_code]\n",
    "\n",
    "    # Check if we have at least one abstract to process\n",
    "    \n",
    "    if df_filtered.empty:\n",
    "        print(f\"No abstracts found for {country_code}. Skipping.\")\n",
    "        return (None, None)\n",
    "\n",
    "    # Vectorize text for those papers using TF-IDF vectorization\n",
    "\n",
    "    X_filtered = vectorizer.transform(df_filtered[\"abstract_text\"])\n",
    "\n",
    "    # Obtain predictions for vectorized text with logistic reg model\n",
    "\n",
    "    y_pred_filtered = model.predict(X_filtered)\n",
    "    \n",
    "    # Obtain total number of papers flagged\n",
    "    \n",
    "    total_flagged = y_pred_filtered.sum()\n",
    "\n",
    "    # Compute percentage of papers flagged as fraudulent for country\n",
    "\n",
    "    percentage_flagged = total_flagged / len(y_pred_filtered) * 100\n",
    "    \n",
    "    # Calculate total number of papers that are actually fraudulent for country\n",
    "    \n",
    "    total_fraud = df_filtered[df_filtered[\"target\"] == 1].shape[0]\n",
    "    \n",
    "    # Calculate percentage of papers that are actually fraudulent for country\n",
    "    \n",
    "    percentage_fraud = total_fraud / df_filtered.shape[0] * 100\n",
    "\n",
    "    # Print results\n",
    "    \n",
    "    #print(f\"Perfectage of papers flagged for {country_code} {percentage_flagged}\")\n",
    "    #print(f\"Perfectage of fraudulent papers for {country_code} {percentage_fraud}\")\n",
    "    \n",
    "    return percentage_flagged, percentage_fraud, total_flagged, total_fraud\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdad04-6386-48bb-b9de-7d893c677c46",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Let us test it to make sure it works OK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4addcec1-d375-478d-a368-03ca717474bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate percentage of papers flagged for US\n",
    "\n",
    "model_tester_country(\"US\", df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ba1fa-5020-4c78-b564-c0c19f96ffe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Now for China\n",
    "\n",
    "model_tester_country(\"CN\", df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ac770-c1dc-47a0-8bdd-1478a39e92dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# UK\n",
    "\n",
    "model_tester_country(\"GB\", df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2583462a-72dd-4776-b20d-b61c571f8e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# India\n",
    "\n",
    "model_tester_country(\"IN\", df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc8466-7c20-4df8-b7d8-002170793df0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Iran\n",
    "\n",
    "model_tester_country(\"IR\", df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dac2aa-c37f-4a4f-abb6-1441a1f1016f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# France\n",
    "\n",
    "model_tester_country(\"AU\", df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d819f3-1a1b-4c44-afa1-55a357f2c2d5",
   "metadata": {},
   "source": [
    "- Let us run a similar quality test for our year breakdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb644a33-7964-4b6f-b04b-4dca14bd5558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_tester_year(year, df, vectorizer, model):\n",
    "    \n",
    "    # Obtain only abstracts for papers from China and store them in data frame\n",
    "\n",
    "    df_filtered = df[df[\"year\"] == year]\n",
    "\n",
    "    # Vectorize text for those papers using TF-IDF vectorization\n",
    "\n",
    "    X_filtered = vectorizer.transform(df_filtered[\"abstract_text\"])\n",
    "\n",
    "    # Obtain predictions for vectorized text with logistic reg model\n",
    "\n",
    "    y_pred_filtered = model.predict(X_filtered)\n",
    "\n",
    "    # Obtain total number of papers flagged\n",
    "    \n",
    "    total_flagged = y_pred_filtered.sum()\n",
    "\n",
    "    # Compute percentage of papers flagged as fraudulent for country\n",
    "\n",
    "    percentage_flagged = total_flagged / len(y_pred_filtered) * 100\n",
    "    \n",
    "    # Calculate total number of papers that are actually fraudulent for country\n",
    "    \n",
    "    total_fraud = df_filtered[df_filtered[\"target\"] == 1].shape[0]\n",
    "    \n",
    "    # Calculate percentage of papers that are actually fraudulent for country\n",
    "    \n",
    "    percentage_fraud = total_fraud / df_filtered.shape[0] * 100\n",
    "    \n",
    "    return percentage_flagged, percentage_fraud, total_flagged, total_fraud\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280f0cc-587c-4b80-b17a-02e17bdee066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_tester_year(2020, df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c133fc5-4bcc-4a62-aa48-693bea1f33ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_tester_year(2019, df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b5c63-5b81-4cb2-b030-59c008696517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_tester_year(2009, df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c5b9bd-eba2-492f-81b7-b4b5a6301fb6",
   "metadata": {},
   "source": [
    "\n",
    "- Finally, let us create a function that allows us to run an analysis for both a country and a year of our choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da0d94-d91e-4289-9d7b-f108b5259576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_tester_year_country(year, country, df, vectorizer, model):\n",
    "    \n",
    "    # Obtain only abstracts for papers from a given bucket and store them in data frame\n",
    "\n",
    "    df_filtered = df[(df[\"year\"] == year) & (df[\"country\"] == country)]\n",
    "\n",
    "    # Vectorize text for those papers using our vectorizer\n",
    "\n",
    "    X_filtered = vectorizer.transform(df_filtered[\"abstract_text\"])\n",
    "\n",
    "    # Obtain predictions for vectorized text with our model\n",
    "\n",
    "    y_pred_filtered = model.predict(X_filtered)\n",
    "\n",
    "    # Obtain total number of papers flagged\n",
    "    \n",
    "    total_flagged = y_pred_filtered.sum()\n",
    "\n",
    "    # Compute percentage of papers flagged as fraudulent for country\n",
    "\n",
    "    percentage_flagged = total_flagged / len(y_pred_filtered) * 100\n",
    "    \n",
    "    # Calculate total number of papers that are actually fraudulent for country\n",
    "    \n",
    "    total_fraud = df_filtered[df_filtered[\"target\"] == 1].shape[0]\n",
    "    \n",
    "    # Calculate percentage of papers that are actually fraudulent for country\n",
    "    \n",
    "    percentage_fraud = total_fraud / df_filtered.shape[0] * 100\n",
    "\n",
    "    # Print results\n",
    "    \n",
    "    #print(f\"Perfectage of papers flagged for {year} and {country} {percentage_flagged}\")\n",
    "    #print(f\"Perfectage of fraudulent papers for {year} and {country} {percentage_fraud}\")\n",
    "    \n",
    "    return percentage_flagged, percentage_fraud, total_flagged, total_fraud\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5e1f3-2163-4ade-a98b-9496092ad18c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model_tester_year_country(2017, \"CN\", df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6552a-80db-4f5d-866d-c34fda9fbe7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model_tester_year_country(2021, \"US\", df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad8347-e24b-48de-9dbe-3bb5733182c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model_tester_year_country(2018, \"IR\", df_corpus, tfidf, log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a5266-15fb-40c4-99a3-f22d4a37a71a",
   "metadata": {},
   "source": [
    "- Let us try a more systematic comparison for all countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80ce62-5fe2-4f25-9389-54304792194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus[\"country\"] = df_corpus[\"country\"].fillna(\"Unknown\")\n",
    "\n",
    "#temporary fix maybe remove later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd9f5a-59f6-4aac-b717-0cb99afb183f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "countries = df_corpus[\"country\"].unique()\n",
    "results = []\n",
    "difference_percentage = []\n",
    "difference_total = []\n",
    "\n",
    "for country in countries:\n",
    "    country_results = model_tester_country(country, df_corpus, tfidf, log_reg)\n",
    "    if country_results is None or len(country_results) < 4:\n",
    "        print(f\"Skipping {country} due to insufficient data.\")\n",
    "        continue\n",
    "    results.append(country_results)\n",
    "    difference_percentage.append(country_results[0] - country_results[1])\n",
    "    difference_total.append(country_results[2] - country_results[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf62e7-b517-4587-9444-c82fe8840590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_differences = pd.DataFrame({\"country\": countries, \"percentage_difference\": difference_percentage, \"total_difference\": difference_total})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4daf3c-2924-4c2f-8029-49a469d636eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_differences = df_differences[df_differences[\"total_difference\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062c32d0-4433-421e-9d8a-341cf9439a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_differences.plot.bar(x=\"country\", y=\"total_difference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d01b43-db2d-4bd9-ab33-96a206f976b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Obtain size of data frame to decide how to filter top entires\n",
    "\n",
    "df_differences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0892e6-c98b-4492-a16c-784ce4a70b14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Filter data frame to obtain countries with most papers in absolute number only \n",
    "\n",
    "df_differences_filtered = df_differences.head(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee11660-ec3d-4c87-be6c-68243fcfa5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make normal plot\n",
    "\n",
    "df_differences.plot.bar(x=\"country\", y=\"percentage_difference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d1928-285b-4e22-9aca-89624bbf4733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Make plot for filtered data frame\n",
    "\n",
    "ax = df_differences_filtered.plot.bar(x=\"country\", y=\"percentage_difference\", color='grey', legend=False)\n",
    "\n",
    "# Set the y axis to -50 and 50 percentage points\n",
    "\n",
    "ax.set_ylim(-70, 70)\n",
    "\n",
    "# Add grid\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "# Display plot\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7c06ef-e0a7-43f7-a262-f692a6926c59",
   "metadata": {},
   "source": [
    "- And now for all years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b332d2-80e7-498e-b486-f4410c97ad5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "year_results = model_tester_year(2020, df_corpus, tfidf, log_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7fc44-41b7-4643-beaa-d22a12987e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "years = df_corpus[\"year\"].unique()\n",
    "results_year = []\n",
    "difference_percentage_year = []\n",
    "difference_total_year = []\n",
    "\n",
    "\n",
    "    \n",
    "for year in years:\n",
    "    year_results = model_tester_year(year, df_corpus, tfidf, log_reg)\n",
    "    results_year.append(year_results)\n",
    "    difference_percentage_year.append(year_results[0] - year_results[1])\n",
    "    difference_total_year.append(year_results[2] - year_results[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f456b4-70c5-4252-bc93-136d544fa177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_differences_year = pd.DataFrame({\"year\": years, \"percentage_difference\": difference_percentage_year, \"total_difference\": difference_total_year})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a0fb7-a742-473b-b194-5f883d51d666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_differences_year.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a68099-6c02-4d3d-a224-a2e8d5b22601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_differences_year.plot.bar(x=\"year\", y=\"percentage_difference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ec55c-f42e-4550-8bd9-0fdc90abdb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_differences_year.plot.bar(x=\"year\", y=\"total_difference\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17bcbf1-378d-4062-9463-cdad63d4390e",
   "metadata": {},
   "source": [
    "-Let us get some scores and performance metrics per year and country too. First we'll try China:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c25e12-d064-4bf4-884c-704606e4db3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_china = df_corpus[df_corpus[\"country\"] == \"CN\"]\n",
    "\n",
    "# Vectorize text for those papers using TF-IDF vectorization\n",
    "\n",
    "X_china = tfidf.transform(df_china[\"abstract_text\"])\n",
    "\n",
    "# Obtain predictions for vectorized text with logistic reg model\n",
    "\n",
    "y_pred_china = log_reg.predict(X_china)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6705f3-3639-4c13-8fb0-aa0669cda911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_china = df_china[\"target\"]\n",
    "\n",
    "report_test = classification_report(y_china, y_pred_china)\n",
    "\n",
    "print(\"Classification Report for China:\\n\", report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c3024a-4130-4edf-847d-a32faabc1fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_matrix_china = confusion_matrix(y_china, y_pred_china)\n",
    "\n",
    "conf_matrix_china"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4006c-434c-4c2c-aebd-3a9a7d1c01d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "- And then the US:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f93d80-a002-4950-9796-26c8e3a908d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_us = df_corpus[df_corpus[\"country\"] == \"US\"]\n",
    "\n",
    "# Vectorize text for those papers using TF-IDF vectorization\n",
    "\n",
    "X_us = tfidf.transform(df_us[\"abstract_text\"])\n",
    "\n",
    "# Obtain predictions for vectorized text with logistic reg model\n",
    "\n",
    "y_pred_us = log_reg.predict(X_us)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148a747-e4ac-4bdd-9e47-a7b12e20db88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_us = df_us[\"target\"]\n",
    "\n",
    "report_test_us = classification_report(y_us, y_pred_us)\n",
    "\n",
    "print(\"Classification Report for the USA:\\n\", report_test_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52fae87-ac76-4c1b-86d1-69d4029e188f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_matrix_us = confusion_matrix(y_us, y_pred_us)\n",
    "\n",
    "conf_matrix_us"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
