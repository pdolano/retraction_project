{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "418cf4ae-80a7-4e3c-ad87-531fe3d60ce4",
   "metadata": {},
   "source": [
    "# 3b. Extracting Country and Year Buckets from Retracted Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f538c-80be-47fd-ab35-c57b8b5c0bdb",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706c66e-dd40-44d1-adc9-1710de33491d",
   "metadata": {},
   "source": [
    "This Notebook analyzes the country and year distribution of our retracted papers and it specifies the number of articles per year and country. In other words, **it extracts the number of retracted papers in each year and country \"bucket\"** for our retracted papers.\n",
    "\n",
    "The Notebook takes as input the .json files for retracted papers that were dowloaded in **Notebook 3**. The bucketing distribution that it produces will in turn be used by **Notebook 4a** to download a set of non-retracted papers with the same year and country distribution as our original retracted paper data set.\n",
    "\n",
    "The **workflow** of the Notebook is therefore set up as follows:\n",
    "\n",
    "- Input: **a set of .json files** with all the bibliographic information that we downloaded from OpenAlex for our retracted papers.\n",
    "\n",
    "- Output: **one .csv file** with the number of retracted papers for each year and country bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d07f2df-447a-43c6-b72f-3a2e771eaf76",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6201d845-96a9-4c08-97de-4db0f357c5d9",
   "metadata": {},
   "source": [
    "- Let us start by importing the various libraries that we will use in the Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62e3d5a-44f3-490f-a408-c46ca9c9a879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c527f00-d9a4-4ee8-ba73-fbecd7673abe",
   "metadata": {},
   "source": [
    "## Input / Output Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f0564-a259-4359-8443-5b415c0d33e7",
   "metadata": {},
   "source": [
    "- Input parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5853a441-d2b9-458b-af32-a001c7964b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# File path of the directory with .json files\n",
    "\n",
    "#input_path = '/Volumes/Hurricane/CellBiology_AllData'\n",
    "\n",
    "input_path = '../data/json_files/cellbiology_retracted_fulljsonfiles'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720dcb6-bfdb-4022-a8d1-a9ee73235ff9",
   "metadata": {},
   "source": [
    "- Output parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4979d5-a6e6-4f58-a3f0-17beb4343eee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# File path for .csv file with results\n",
    "\n",
    "output_path = '../data/results.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6613abda-3be8-4b3a-a477-0f7a0aa035e7",
   "metadata": {},
   "source": [
    "## Extracting Year and Country Buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb7d0ae-7131-4b7c-bd8b-26a4d094c2f1",
   "metadata": {},
   "source": [
    "\n",
    "- We can now go ahead and analyze the .json files for our retracted papers and find the amount of papers per year and country bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8b4b72-70cd-491b-ad2c-777eb380d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete and saved to .csv file in ../data/results.csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create list with name of headers to be written in out output .csv file\n",
    "\n",
    "headers = ['file_name', 'author_country', 'publication_year', 'abstract_info', 'ngram_info', 'error']\n",
    "\n",
    "# Open .csv file to write values for each bucket\n",
    "\n",
    "with open(output_path, mode='w', newline='') as file:\n",
    "    \n",
    "    # Initialize writer\n",
    "    \n",
    "    writer = csv.DictWriter(file, fieldnames=headers)\n",
    "    \n",
    "    # Write header names\n",
    "    \n",
    "    writer.writeheader() \n",
    "\n",
    "    # Create loop to iterate over all .json files in input directory\n",
    "    \n",
    "    for filename in os.listdir(input_path):\n",
    "        \n",
    "        # If clause to make sure we only loop through .json files\n",
    "        \n",
    "        if filename.endswith('.json'):\n",
    "            \n",
    "            # Construct full file path for current .json file in loop iteration\n",
    "            \n",
    "            file_path = os.path.join(input_path, filename)\n",
    "                        \n",
    "            # Initialize error message and other variables\n",
    "            \n",
    "            error_message = \"\"\n",
    "            \n",
    "            author_country = \"N/A\"\n",
    "            \n",
    "            ngram_info = False\n",
    "\n",
    "            # Try to open and read .json file in current loop iteration\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "                    \n",
    "                    # Read .json file and dump into \n",
    "                    \n",
    "                    content = json_file.read()\n",
    "                    \n",
    "                    # If clause to account for situation in which .json file is empty\n",
    "                    \n",
    "                    if not content:\n",
    "                        \n",
    "                        raise ValueError(\"File is empty\")\n",
    "                        \n",
    "                    # Load content of current .json file into data variable\n",
    "                        \n",
    "                    data = json.loads(content)\n",
    "                    \n",
    "            # Clause to update error message if reading of .json file fails\n",
    "\n",
    "            except Exception as e:\n",
    "                \n",
    "                error_message = str(e)\n",
    "                \n",
    "        # Extract the country code from data variable\n",
    "                    \n",
    "        if 'authorships' in data:\n",
    "                        \n",
    "            for authorship in data['authorships']:\n",
    "                            \n",
    "                if 'institutions' in authorship and any(inst.get('country_code') for inst in authorship['institutions']):\n",
    "                                \n",
    "                    author_country = next((inst['country_code'] for inst in authorship['institutions'] if 'country_code' in inst), \"N/A\")\n",
    "                                \n",
    "                    break\n",
    "                    \n",
    "        # Extract ngrams information from data variable \n",
    "                    \n",
    "        ngrams_url = data.get('ngrams_url', '')\n",
    "                    \n",
    "        if ngrams_url.startswith('https://api.'):\n",
    "                        \n",
    "            ngram_info = True\n",
    "\n",
    "        # Extract publication year from data variable\n",
    "            \n",
    "        publication_year = data.get('publication_year', 'N/A') if not error_message else 'N/A'\n",
    "        \n",
    "        # Extract abstract info from data variable\n",
    "\n",
    "        abstract_info = bool(data.get('abstract_inverted_index')) if not error_message else False\n",
    "\n",
    "        # Write data or error to .csv file\n",
    "            \n",
    "        writer.writerow({\n",
    "            'file_name': filename,\n",
    "            'author_country': author_country,\n",
    "            'publication_year': publication_year,\n",
    "            'abstract_info': abstract_info,\n",
    "            'ngram_info': ngram_info,\n",
    "            'error': error_message\n",
    "        })\n",
    "\n",
    "# Write confirmation message\n",
    "\n",
    "print(f\"Data processing complete and saved to .csv file in {output_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
